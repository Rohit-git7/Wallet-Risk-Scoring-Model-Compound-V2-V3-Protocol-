{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8ZtLvk5mu_M",
        "outputId": "d7e25d31-29dc-4722-9000-6fd7666b9bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Transaction Data Retrieval \n",
            "Successfully loaded 103 wallet addresses\n",
            "Generating realistic transaction data \n",
            "Processed 20/103 wallets...\n",
            "Processed 40/103 wallets...\n",
            "Processed 60/103 wallets...\n",
            "Processed 80/103 wallets...\n",
            "Processed 100/103 wallets...\n",
            "Generated 1144 transactions with realistic risk patterns\n",
            "Risk profile distribution:\n",
            "  medium_risk: 53 wallets (51.5%)\n",
            "  low_risk: 29 wallets (28.2%)\n",
            "  high_risk: 21 wallets (20.4%)\n",
            "\n",
            "Validating transaction data quality\n",
            "Data Quality Report:\n",
            "  Total transactions: 1144\n",
            "  Unique wallets: 103\n",
            "  Date range: 2025-01-29 to 2025-07-26\n",
            "  Avg transactions per wallet: 11.1\n",
            "  Overall success rate: 81.56%\n",
            "  Token diversity: 5 tokens\n",
            "  Amount range: $50.00 - $12101.58\n",
            "  Average amount: $818.87\n",
            "\n",
            "Action distribution:\n",
            "  repay: 322 (28.1%)\n",
            "  supply: 290 (25.3%)\n",
            "  borrow: 278 (24.3%)\n",
            "  withdraw: 254 (22.2%)\n",
            "\n",
            "Transaction data saved to: compound_transactions_ml.csv\n",
            "Done\n",
            "\n",
            "Sample Transaction Data (10 rows):\n",
            " wallet_address compound_token   action  amount_usd  success  gas_price_gwei wallet_risk_profile\n",
            "0x0039f22efb...           cETH    repay      225.68     True           65.57         medium_risk\n",
            "0x0039f22efb...           cDAI   borrow      238.61     True           90.53         medium_risk\n",
            "0x0039f22efb...          cUSDC   borrow      559.39     True           78.47         medium_risk\n",
            "0x0039f22efb...          cUSDC   supply      372.00     True           55.97         medium_risk\n",
            "0x0039f22efb...          cUSDT withdraw     2790.12     True           63.18         medium_risk\n",
            "0x0039f22efb...          cWBTC withdraw      437.45     True           19.13         medium_risk\n",
            "0x0039f22efb...           cDAI   supply      739.61    False           96.73         medium_risk\n",
            "0x0039f22efb...          cWBTC   supply       57.73    False           85.50         medium_risk\n",
            "0x0039f22efb...          cUSDC   supply      588.33     True           75.70         medium_risk\n",
            "0x0039f22efb...           cDAI   supply     2103.49    False           44.75         medium_risk\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# transaction retrieval\n",
        "class CompoundTransactionRetriever:\n",
        "    def __init__(self, wallet_file: str = \"/content/Wallet id .csv\"):\n",
        "        self.wallet_file = wallet_file\n",
        "        self.transactions_df = None\n",
        "\n",
        "# Load wallet addresses from CSV file\n",
        "    def load_wallet_addresses(self):\n",
        "        try:\n",
        "            df = pd.read_csv(self.wallet_file)\n",
        "# Getting first column and converting to lowercase\n",
        "            wallets = df.iloc[:, 0].str.lower().tolist()\n",
        "            print(f\"Successfully loaded {len(wallets)} wallet addresses\")\n",
        "            return wallets\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading wallet file: {e}\")\n",
        "            return []\n",
        "\n",
        "# Generate realistic transaction data for training model\n",
        "    def generate_ml_optimized_transactions(self, wallets):\n",
        "        np.random.seed(42)\n",
        "        transactions = []\n",
        "        compound_tokens = ['cUSDC', 'cETH', 'cDAI', 'cUSDT', 'cWBTC']\n",
        "        actions = ['supply', 'withdraw', 'borrow', 'repay']\n",
        "\n",
        "        print(\"Generating realistic transaction data \")\n",
        "\n",
        "# Creating distinct risk profiles\n",
        "        for i, wallet in enumerate(wallets):\n",
        "            risk_profile = np.random.choice(['low_risk', 'medium_risk', 'high_risk'],\n",
        "                                          p=[0.3, 0.5, 0.2])\n",
        "\n",
        "# Number of transactions based on risk profile\n",
        "            if risk_profile == 'high_risk':\n",
        "                num_txs = np.random.poisson(12) + 5  # 5-25 transactions\n",
        "                success_rate = 0.65\n",
        "                amount_multiplier = 2.0\n",
        "                gas_multiplier = 1.8\n",
        "            elif risk_profile == 'medium_risk':\n",
        "                num_txs = np.random.poisson(8) + 3  # 3-18 transactions\n",
        "                success_rate = 0.82\n",
        "                amount_multiplier = 1.0\n",
        "                gas_multiplier = 1.0\n",
        "            else:  # low_risk\n",
        "                num_txs = np.random.poisson(6) + 2  # 2-15 transactions\n",
        "                success_rate = 0.95  # High success rate\n",
        "                amount_multiplier = 0.7\n",
        "                gas_multiplier = 0.6\n",
        "\n",
        "# Generate transaction based on risk profile\n",
        "            for _ in range(num_txs):\n",
        "                base_amount = np.random.lognormal(6, 1)  # Log-normal distribution for realistic amounts\n",
        "                amount_usd = base_amount * amount_multiplier\n",
        "                amount_usd = np.clip(amount_usd, 50, 50000)\n",
        "\n",
        "# Gas usage correlated with amount and risk\n",
        "                gas_used = np.random.randint(50000, 300000)\n",
        "                gas_price = np.random.uniform(10, 100) * gas_multiplier\n",
        "\n",
        "# Success based on risk profile\n",
        "                success = np.random.random() < success_rate\n",
        "\n",
        "# Random timestamp within last 6 months\n",
        "                days_back = np.random.randint(1, 180)\n",
        "                timestamp = datetime.now() - timedelta(days=days_back)\n",
        "\n",
        "                transaction = {\n",
        "                    'wallet_address': wallet,\n",
        "                    'hash': f\"0x{''.join(np.random.choice(list('0123456789abcdef'), 64))}\",\n",
        "                    'compound_token': np.random.choice(compound_tokens),\n",
        "                    'action': np.random.choice(actions),\n",
        "                    'amount_usd': round(amount_usd, 2),\n",
        "                    'gas_used': gas_used,\n",
        "                    'gas_price_gwei': round(gas_price, 2),\n",
        "                    'success': success,\n",
        "                    'timestamp': int(timestamp.timestamp()),\n",
        "                    'datetime': timestamp,\n",
        "                    'block_number': np.random.randint(16000000, 18500000),\n",
        "                    'wallet_risk_profile': risk_profile  # Ground truth for ML\n",
        "                }\n",
        "\n",
        "                transactions.append(transaction)\n",
        "\n",
        "# Progress indicator\n",
        "            if (i + 1) % 20 == 0:\n",
        "                print(f\"Processed {i + 1}/{len(wallets)} wallets...\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "        df = pd.DataFrame(transactions)\n",
        "\n",
        "        print(f\"Generated {len(df)} transactions with realistic risk patterns\")\n",
        "        print(f\"Risk profile distribution:\")\n",
        "        profile_counts = df.groupby('wallet_address')['wallet_risk_profile'].first().value_counts()\n",
        "        for profile, count in profile_counts.items():\n",
        "            pct = (count / len(wallets)) * 100\n",
        "            print(f\"  {profile}: {count} wallets ({pct:.1f}%)\")\n",
        "\n",
        "        return df\n",
        "\n",
        "# Checking generated data quality\n",
        "    def validate_transaction_data(self, df):\n",
        "        print(\"\\nValidating transaction data quality\")\n",
        "\n",
        "        validation_results = {\n",
        "            'total_transactions': len(df),\n",
        "            'unique_wallets': df['wallet_address'].nunique(),\n",
        "            'date_range': f\"{df['datetime'].min().date()} to {df['datetime'].max().date()}\",\n",
        "            'avg_txs_per_wallet': len(df) / df['wallet_address'].nunique(),\n",
        "            'success_rate': df['success'].mean(),\n",
        "            'token_diversity': df['compound_token'].nunique(),\n",
        "            'action_distribution': df['action'].value_counts().to_dict(),\n",
        "            'amount_range': f\"${df['amount_usd'].min():.2f} - ${df['amount_usd'].max():.2f}\",\n",
        "            'avg_amount': f\"${df['amount_usd'].mean():.2f}\"\n",
        "        }\n",
        "\n",
        "        print(\"Data Quality Report:\")\n",
        "        print(f\"  Total transactions: {validation_results['total_transactions']}\")\n",
        "        print(f\"  Unique wallets: {validation_results['unique_wallets']}\")\n",
        "        print(f\"  Date range: {validation_results['date_range']}\")\n",
        "        print(f\"  Avg transactions per wallet: {validation_results['avg_txs_per_wallet']:.1f}\")\n",
        "        print(f\"  Overall success rate: {validation_results['success_rate']:.2%}\")\n",
        "        print(f\"  Token diversity: {validation_results['token_diversity']} tokens\")\n",
        "        print(f\"  Amount range: {validation_results['amount_range']}\")\n",
        "        print(f\"  Average amount: {validation_results['avg_amount']}\")\n",
        "\n",
        "        print(\"\\nAction distribution:\")\n",
        "        for action, count in validation_results['action_distribution'].items():\n",
        "            pct = (count / validation_results['total_transactions']) * 100\n",
        "            print(f\"  {action}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "        return validation_results\n",
        "\n",
        "# Saving transaction data\n",
        "    def save_transaction_data(self, df, filename=\"compound_transactions_ml.csv\"):\n",
        "        save_df = df.copy()\n",
        "        save_df['datetime'] = save_df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S') #datetime to string for csv formatt\n",
        "\n",
        "        save_df.to_csv(filename, index=False)\n",
        "        print(f\"\\nTransaction data saved to: {filename}\")\n",
        "\n",
        "        return filename\n",
        "\n",
        "    def retrieve_transaction_data(self):\n",
        "        print(\" Transaction Data Retrieval \")\n",
        "        wallets = self.load_wallet_addresses()\n",
        "\n",
        "        if not wallets:\n",
        "            print(\"No wallets loaded. Please check your Wallet-id.csv file.\")\n",
        "            return None\n",
        "\n",
        "# Generating ML-optimized transaction data\n",
        "        self.transactions_df = self.generate_ml_optimized_transactions(wallets)\n",
        "\n",
        "# Data quality validation\n",
        "        validation_results = self.validate_transaction_data(self.transactions_df)\n",
        "        filename = self.save_transaction_data(self.transactions_df)\n",
        "\n",
        "        print(f\"Done\")\n",
        "\n",
        "        return self.transactions_df, validation_results\n",
        "\n",
        "# Display of data\n",
        "    def display_sample_data(self, n_samples=10):\n",
        "        if self.transactions_df is None:\n",
        "            print(\"No transaction data available. Run retrieve_transaction_data() first.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nSample Transaction Data ({n_samples} rows):\")\n",
        "        sample_cols = ['wallet_address', 'compound_token', 'action', 'amount_usd',\n",
        "                      'success', 'gas_price_gwei', 'wallet_risk_profile']\n",
        "\n",
        "        sample_df = self.transactions_df[sample_cols].head(n_samples).copy()\n",
        "        sample_df['wallet_address'] = sample_df['wallet_address'].str[:12] + '...'\n",
        "\n",
        "        print(sample_df.to_string(index=False))\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "\n",
        "    retriever = CompoundTransactionRetriever()\n",
        "    transaction_data, validation_results = retriever.retrieve_transaction_data()\n",
        "    retriever.display_sample_data()\n",
        "    return retriever, transaction_data, validation_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    retriever, transaction_data, validation_results = main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Feature Engineering def\n",
        "class CompoundMLFeatureEngineer:\n",
        "    def __init__(self, transaction_file: str = \"compound_transactions_ml.csv\"):\n",
        "        self.transaction_file = transaction_file\n",
        "        self.transactions_df = None\n",
        "        self.features_df = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "# Transaction data retrieval\n",
        "    def load_transaction_data(self):\n",
        "        try:\n",
        "            self.transactions_df = pd.read_csv(self.transaction_file)\n",
        "            self.transactions_df['datetime'] = pd.to_datetime(self.transactions_df['datetime'])\n",
        "            print(f\"Loaded {len(self.transactions_df)} transactions for feature engineering\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading transaction data: {e}\")\n",
        "            return False\n",
        "\n",
        "# Calculate comprehensive features for each wallet\n",
        "    def calculate_wallet_features(self):\n",
        "        print(\"Engineering ML features for each wallet \")\n",
        "\n",
        "        wallet_features = []\n",
        "\n",
        "        for wallet in self.transactions_df['wallet_address'].unique():\n",
        "            wallet_data = self.transactions_df[self.transactions_df['wallet_address'] == wallet].copy()\n",
        "\n",
        "# Sort by datetime for time-series features\n",
        "            wallet_data = wallet_data.sort_values('datetime')\n",
        "\n",
        "            total_transactions = len(wallet_data)\n",
        "            successful_transactions = wallet_data['success'].sum()\n",
        "            failed_transactions = total_transactions - successful_transactions\n",
        "            success_rate = successful_transactions / total_transactions\n",
        "\n",
        "# Volume and amount features\n",
        "            total_volume = wallet_data['amount_usd'].sum()\n",
        "            avg_transaction_amount = wallet_data['amount_usd'].mean()\n",
        "            max_transaction_amount = wallet_data['amount_usd'].max()\n",
        "            min_transaction_amount = wallet_data['amount_usd'].min()\n",
        "            amount_std = wallet_data['amount_usd'].std()\n",
        "            amount_cv = amount_std / avg_transaction_amount if avg_transaction_amount > 0 else 0\n",
        "\n",
        "# Action-based features\n",
        "            action_counts = wallet_data['action'].value_counts()\n",
        "            supply_count = action_counts.get('supply', 0)\n",
        "            borrow_count = action_counts.get('borrow', 0)\n",
        "            withdraw_count = action_counts.get('withdraw', 0)\n",
        "            repay_count = action_counts.get('repay', 0)\n",
        "\n",
        "# Volume by action\n",
        "            supply_volume = wallet_data[wallet_data['action'] == 'supply']['amount_usd'].sum()\n",
        "            borrow_volume = wallet_data[wallet_data['action'] == 'borrow']['amount_usd'].sum()\n",
        "            withdraw_volume = wallet_data[wallet_data['action'] == 'withdraw']['amount_usd'].sum()\n",
        "            repay_volume = wallet_data[wallet_data['action'] == 'repay']['amount_usd'].sum()\n",
        "\n",
        "# Risk ratios - K feature\n",
        "            borrow_to_supply_ratio = borrow_volume / supply_volume if supply_volume > 0 else 0\n",
        "            repay_to_borrow_ratio = repay_volume / borrow_volume if borrow_volume > 0 else 1\n",
        "            withdraw_to_supply_ratio = withdraw_volume / supply_volume if supply_volume > 0 else 0\n",
        "\n",
        "# Gas usage patterns\n",
        "            avg_gas_price = wallet_data['gas_price_gwei'].mean()\n",
        "            max_gas_price = wallet_data['gas_price_gwei'].max()\n",
        "            gas_price_std = wallet_data['gas_price_gwei'].std()\n",
        "            high_gas_transactions = len(wallet_data[wallet_data['gas_price_gwei'] > wallet_data['gas_price_gwei'].quantile(0.75)])\n",
        "\n",
        "# Token diversity and behavior\n",
        "            unique_tokens = wallet_data['compound_token'].nunique()\n",
        "            most_used_token = wallet_data['compound_token'].mode().iloc[0]\n",
        "            token_concentration = (wallet_data['compound_token'] == most_used_token).sum() / total_transactions\n",
        "\n",
        "# Time-based features\n",
        "            first_transaction = wallet_data['datetime'].min()\n",
        "            last_transaction = wallet_data['datetime'].max()\n",
        "            activity_span_days = (last_transaction - first_transaction).days + 1\n",
        "            transactions_per_day = total_transactions / activity_span_days if activity_span_days > 0 else 0\n",
        "\n",
        "# Recent activity (last 30 days)\n",
        "            recent_cutoff = datetime.now() - pd.Timedelta(days=30)\n",
        "            recent_transactions = len(wallet_data[wallet_data['datetime'] >= recent_cutoff])\n",
        "            recent_activity_ratio = recent_transactions / total_transactions\n",
        "\n",
        "# Behavioral pattern features\n",
        "            large_transaction_threshold = avg_transaction_amount * 2\n",
        "            large_transaction_count = len(wallet_data[wallet_data['amount_usd'] > large_transaction_threshold])\n",
        "            large_transaction_ratio = large_transaction_count / total_transactions\n",
        "\n",
        "# Failed transaction patterns\n",
        "            failed_transaction_ratio = failed_transactions / total_transactions\n",
        "            consecutive_failures = self.calculate_consecutive_failures(wallet_data)\n",
        "\n",
        "# Advanced features\n",
        "            transaction_frequency_std = self.calculate_frequency_variance(wallet_data)\n",
        "            amount_trend = self.calculate_amount_trend(wallet_data)\n",
        "            success_rate_trend = self.calculate_success_trend(wallet_data)\n",
        "            risk_profile = wallet_data['wallet_risk_profile'].iloc[0]\n",
        "\n",
        "# Compile all features\n",
        "            features = {\n",
        "                'wallet_address': wallet,\n",
        "                'total_transactions': total_transactions,\n",
        "                'success_rate': success_rate,\n",
        "                'failed_transaction_ratio': failed_transaction_ratio,\n",
        "                'total_volume_usd': total_volume,\n",
        "                'avg_transaction_amount': avg_transaction_amount,\n",
        "                'max_transaction_amount': max_transaction_amount,\n",
        "                'min_transaction_amount': min_transaction_amount,\n",
        "                'amount_std': amount_std,\n",
        "                'amount_cv': amount_cv,\n",
        "                'supply_count': supply_count,\n",
        "                'borrow_count': borrow_count,\n",
        "                'withdraw_count': withdraw_count,\n",
        "                'repay_count': repay_count,\n",
        "                'supply_volume': supply_volume,\n",
        "                'borrow_volume': borrow_volume,\n",
        "                'withdraw_volume': withdraw_volume,\n",
        "                'repay_volume': repay_volume,\n",
        "                'borrow_to_supply_ratio': borrow_to_supply_ratio,\n",
        "                'repay_to_borrow_ratio': repay_to_borrow_ratio,\n",
        "                'withdraw_to_supply_ratio': withdraw_to_supply_ratio,\n",
        "                'avg_gas_price': avg_gas_price,\n",
        "                'max_gas_price': max_gas_price,\n",
        "                'gas_price_std': gas_price_std,\n",
        "                'high_gas_transactions': high_gas_transactions,\n",
        "                'unique_tokens': unique_tokens,\n",
        "                'token_concentration': token_concentration,\n",
        "                'activity_span_days': activity_span_days,\n",
        "                'transactions_per_day': transactions_per_day,\n",
        "                'recent_activity_ratio': recent_activity_ratio,\n",
        "                'large_transaction_ratio': large_transaction_ratio,\n",
        "                'consecutive_failures': consecutive_failures,\n",
        "                'transaction_frequency_std': transaction_frequency_std,\n",
        "                'amount_trend': amount_trend,\n",
        "                'success_rate_trend': success_rate_trend,\n",
        "                'risk_profile': risk_profile,  # Ground truth for ML\n",
        "                'most_used_token': most_used_token\n",
        "            }\n",
        "\n",
        "            wallet_features.append(features)\n",
        "\n",
        "        return pd.DataFrame(wallet_features)\n",
        "\n",
        "# Calculating maximum consecutive failed transa\n",
        "    def calculate_consecutive_failures(self, wallet_data):\n",
        "        failures = (~wallet_data['success']).astype(int)\n",
        "        max_consecutive = 0\n",
        "        current_consecutive = 0\n",
        "\n",
        "        for failure in failures:\n",
        "            if failure == 1:\n",
        "                current_consecutive += 1\n",
        "                max_consecutive = max(max_consecutive, current_consecutive)\n",
        "            else:\n",
        "                current_consecutive = 0\n",
        "\n",
        "        return max_consecutive\n",
        "\n",
        "    def calculate_frequency_variance(self, wallet_data):\n",
        "        if len(wallet_data) < 2:\n",
        "            return 0\n",
        "\n",
        "        wallet_data = wallet_data.sort_values('datetime')\n",
        "        time_diffs = wallet_data['datetime'].diff().dt.total_seconds() / 3600  # Hours\n",
        "        time_diffs = time_diffs.dropna()\n",
        "\n",
        "        return time_diffs.std() if len(time_diffs) > 0 else 0\n",
        "\n",
        "# Calculate trend in transaction amounts over time\n",
        "    def calculate_amount_trend(self, wallet_data):\n",
        "        if len(wallet_data) < 2:\n",
        "            return 0\n",
        "\n",
        "        wallet_data = wallet_data.sort_values('datetime').reset_index(drop=True)\n",
        "        x = np.arange(len(wallet_data))\n",
        "        y = wallet_data['amount_usd'].values\n",
        "\n",
        "# Simple linear regression slope\n",
        "        if len(x) > 1:\n",
        "            slope = np.polyfit(x, y, 1)[0]\n",
        "            return slope\n",
        "        return 0\n",
        "\n",
        "# Trend in success rate/time\n",
        "    def calculate_success_trend(self, wallet_data):\n",
        "        if len(wallet_data) < 3:\n",
        "            return 0\n",
        "        wallet_data = wallet_data.sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "# Rolling success rate\n",
        "        window_size = min(5, len(wallet_data) // 2)\n",
        "        if window_size < 2:\n",
        "            return 0\n",
        "\n",
        "        rolling_success = wallet_data['success'].rolling(window=window_size).mean()\n",
        "        rolling_success = rolling_success.dropna()\n",
        "\n",
        "        if len(rolling_success) < 2:\n",
        "            return 0\n",
        "\n",
        "# Calculate trend\n",
        "        x = np.arange(len(rolling_success))\n",
        "        y = rolling_success.values\n",
        "        slope = np.polyfit(x, y, 1)[0]\n",
        "\n",
        "        return slope\n",
        "\n",
        "# Encoding features\n",
        "    def encode_categorical_features(self, features_df):\n",
        "        features_df['risk_label'] = self.label_encoder.fit_transform(features_df['risk_profile'])\n",
        "        token_dummies = pd.get_dummies(features_df['most_used_token'], prefix='token') # One-hot encode\n",
        "        features_df = pd.concat([features_df, token_dummies], axis=1)\n",
        "\n",
        "        return features_df\n",
        "\n",
        "# Creating binary risk indicator features\n",
        "    def create_risk_indicators(self, features_df):\n",
        "        features_df['high_leverage_risk'] = (features_df['borrow_to_supply_ratio'] > 0.7).astype(int)\n",
        "        features_df['poor_repayment_risk'] = (features_df['repay_to_borrow_ratio'] < 0.8).astype(int)\n",
        "        features_df['high_failure_risk'] = (features_df['failed_transaction_ratio'] > 0.2).astype(int)\n",
        "        features_df['low_activity_risk'] = (features_df['transactions_per_day'] < 0.1).astype(int)\n",
        "        gas_threshold = features_df['avg_gas_price'].quantile(0.75)\n",
        "        features_df['high_gas_risk'] = (features_df['avg_gas_price'] > gas_threshold).astype(int)\n",
        "        features_df['concentration_risk'] = (features_df['token_concentration'] > 0.8).astype(int)\n",
        "        features_df['large_tx_risk'] = (features_df['large_transaction_ratio'] > 0.3).astype(int)\n",
        "        features_df['volatility_risk'] = (features_df['amount_cv'] > features_df['amount_cv'].quantile(0.75)).astype(int)\n",
        "\n",
        "        return features_df\n",
        "\n",
        "    def prepare_ml_features(self):\n",
        "        print(\" ML Feature Engineering Pipeline \\n\")\n",
        "\n",
        "        if not self.load_transaction_data():\n",
        "            return None\n",
        "\n",
        "        self.features_df = self.calculate_wallet_features()\n",
        "        self.features_df = self.encode_categorical_features(self.features_df)\n",
        "        self.features_df = self.create_risk_indicators(self.features_df)\n",
        "\n",
        "# Handle missing values\n",
        "        numeric_columns = self.features_df.select_dtypes(include=[np.number]).columns\n",
        "        self.features_df[numeric_columns] = self.features_df[numeric_columns].fillna(0)\n",
        "\n",
        "# Save processed features\n",
        "        self.features_df.to_csv(\"ml_wallet_features.csv\", index=False)\n",
        "        print(\"Saved ML features to: ml_wallet_features.csv\")\n",
        "\n",
        "        return self.features_df\n",
        "\n",
        "# Display features\n",
        "    def display_feature_summary(self):\n",
        "        if self.features_df is None:\n",
        "            print(\"No features available. Run prepare_ml_features() first.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n Feature Engineering Summary \")\n",
        "        print(f\"\\nDataset Overview:\")\n",
        "        print(f\"Total wallets: {len(self.features_df)}\")\n",
        "        print(f\"Total features: {len(self.features_df.columns) - 3}\")  # Exclude wallet_address, risk_profile, risk_label\n",
        "\n",
        "# Risk distribution\n",
        "        print(f\"\\nRisk Label Distribution:\")\n",
        "        risk_dist = self.features_df['risk_profile'].value_counts()\n",
        "        for risk_type, count in risk_dist.items():\n",
        "            pct = (count / len(self.features_df)) * 100\n",
        "            print(f\"  {risk_type}: {count} wallets ({pct:.1f}%)\")\n",
        "\n",
        "        print(f\"\\nKey Feature Statistics:\")\n",
        "        key_features = ['success_rate', 'borrow_to_supply_ratio', 'repay_to_borrow_ratio',\n",
        "                       'failed_transaction_ratio', 'unique_tokens', 'transactions_per_day']\n",
        "\n",
        "        for feature in key_features:\n",
        "            if feature in self.features_df.columns:\n",
        "                mean_val = self.features_df[feature].mean()\n",
        "                std_val = self.features_df[feature].std()\n",
        "                print(f\"  {feature}: {mean_val:.3f} ± {std_val:.3f}\")\n",
        "\n",
        "# Risk indicators\n",
        "        print(f\"\\nRisk Indicator Distribution:\")\n",
        "        risk_indicators = [col for col in self.features_df.columns if col.endswith('_risk')]\n",
        "        for indicator in risk_indicators:\n",
        "            count = self.features_df[indicator].sum()\n",
        "            pct = (count / len(self.features_df)) * 100\n",
        "            print(f\"  {indicator}: {count} wallets ({pct:.1f}%)\")\n",
        "\n",
        "# Sample data\n",
        "        print(f\"\\nSample Processed Features:\")\n",
        "        display_cols = ['wallet_address', 'risk_profile', 'success_rate', 'borrow_to_supply_ratio',\n",
        "                       'high_leverage_risk', 'high_failure_risk', 'total_transactions']\n",
        "\n",
        "        sample_df = self.features_df[display_cols].head(8).copy()\n",
        "        sample_df['wallet_address'] = sample_df['wallet_address'].str[:12] + '...'\n",
        "\n",
        "        print(sample_df.to_string(index=False))\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "\n",
        "    engineer = CompoundMLFeatureEngineer()\n",
        "    features_df = engineer.prepare_ml_features()\n",
        "\n",
        "    if features_df is not None:\n",
        "        engineer.display_feature_summary()\n",
        "\n",
        "        print(f\"Output file: ml_wallet_features.csv\")\n",
        "\n",
        "    return engineer, features_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    engineer, features_df = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC3fF_ttoUnj",
        "outputId": "9bcaf7cd-63c8-4e79-f761-62a8d1f2aa4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ML Feature Engineering Pipeline \n",
            "\n",
            "Loaded 1144 transactions for feature engineering\n",
            "Engineering ML features for each wallet \n",
            "Saved ML features to: ml_wallet_features.csv\n",
            "\n",
            " Feature Engineering Summary \n",
            "\n",
            "Dataset Overview:\n",
            "Total wallets: 103\n",
            "Total features: 48\n",
            "\n",
            "Risk Label Distribution:\n",
            "  medium_risk: 53 wallets (51.5%)\n",
            "  low_risk: 29 wallets (28.2%)\n",
            "  high_risk: 21 wallets (20.4%)\n",
            "\n",
            "Key Feature Statistics:\n",
            "  success_rate: 0.841 ± 0.141\n",
            "  borrow_to_supply_ratio: 1.786 ± 3.980\n",
            "  repay_to_borrow_ratio: 2.801 ± 4.756\n",
            "  failed_transaction_ratio: 0.159 ± 0.141\n",
            "  unique_tokens: 4.369 ± 0.741\n",
            "  transactions_per_day: 0.078 ± 0.025\n",
            "\n",
            "Risk Indicator Distribution:\n",
            "  high_leverage_risk: 52 wallets (50.5%)\n",
            "  poor_repayment_risk: 37 wallets (35.9%)\n",
            "  high_failure_risk: 37 wallets (35.9%)\n",
            "  low_activity_risk: 84 wallets (81.6%)\n",
            "  high_gas_risk: 26 wallets (25.2%)\n",
            "  concentration_risk: 0 wallets (0.0%)\n",
            "  large_tx_risk: 0 wallets (0.0%)\n",
            "  volatility_risk: 26 wallets (25.2%)\n",
            "\n",
            "Sample Processed Features:\n",
            " wallet_address risk_profile  success_rate  borrow_to_supply_ratio  high_leverage_risk  high_failure_risk  total_transactions\n",
            "0x0039f22efb...  medium_risk      0.700000                0.206674                   0                  1                  10\n",
            "0x06b51c6882...  medium_risk      1.000000                3.798512                   1                  0                   7\n",
            "0x0795732aac...  medium_risk      0.750000                4.621748                   1                  1                  12\n",
            "0x0aaa79f1a8...     low_risk      1.000000                0.000000                   0                  0                   3\n",
            "0x0fe383e5ab...  medium_risk      0.833333                1.094450                   1                  0                   6\n",
            "0x104ae61d8d...  medium_risk      0.700000                0.221308                   0                  1                  10\n",
            "0x111c7208a7...     low_risk      0.916667                5.546159                   1                  0                  12\n",
            "0x124853fecb...  medium_risk      0.750000                0.878627                   1                  1                   8\n",
            "Output file: ml_wallet_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import classification_report, brier_score_loss\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Logistic regression risk scoring model def\n",
        "class LogisticRegressionRiskModel:\n",
        "    def __init__(self, features_file: str = \"ml_wallet_features.csv\"):\n",
        "        self.features_file = features_file\n",
        "        self.features_df = None\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.calibrated_model = None\n",
        "\n",
        "# Load features, selecting feature columns, preparing features and target\n",
        "    def load_and_prepare_data(self):\n",
        "\n",
        "        self.features_df = pd.read_csv(self.features_file)\n",
        "        print(f\"Loaded {len(self.features_df)} wallets\")\n",
        "        exclude_cols = ['wallet_address', 'risk_profile', 'risk_label', 'most_used_token']\n",
        "        feature_cols = [col for col in self.features_df.columns if col not in exclude_cols]\n",
        "\n",
        "        self.X = self.features_df[feature_cols].fillna(0)\n",
        "        self.y = self.features_df['risk_label']\n",
        "\n",
        "        print(f\"Features: {self.X.shape[1]}, Samples: {self.X.shape[0]}\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "# Training the model\n",
        "    def train_logistic_regression(self):\n",
        "        print(\"Training Logistic Regression model...\")\n",
        "\n",
        "# Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            self.X, self.y, test_size=0.25, random_state=42, stratify=self.y\n",
        "        )\n",
        "\n",
        "# Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "# Using different regularization strengths\n",
        "        best_score = 0\n",
        "        best_C = 1.0\n",
        "\n",
        "        for C in [0.1, 0.5, 1.0, 2.0, 5.0]:\n",
        "            model = LogisticRegression(\n",
        "                C=C,\n",
        "                random_state=42,\n",
        "                class_weight='balanced',\n",
        "                max_iter=1000,\n",
        "                multi_class='multinomial',\n",
        "                solver='lbfgs'\n",
        "            )\n",
        "\n",
        "# Cross-validation\n",
        "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "            mean_score = cv_scores.mean()\n",
        "\n",
        "            print(f\"C={C}: CV Score = {mean_score:.4f}\")\n",
        "\n",
        "            if mean_score > best_score:\n",
        "                best_score = mean_score\n",
        "                best_C = C\n",
        "\n",
        "        self.model = LogisticRegression(\n",
        "            C=best_C,\n",
        "            random_state=42,\n",
        "            class_weight='balanced',\n",
        "            max_iter=1000,\n",
        "            multi_class='multinomial',\n",
        "            solver='lbfgs'\n",
        "        )\n",
        "\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Test accuracy\n",
        "        test_accuracy = self.model.score(X_test_scaled, y_test)\n",
        "\n",
        "        print(f\"Best C: {best_C}\")\n",
        "        print(f\"Best CV Score: {best_score:.4f}\")\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        return X_test_scaled, y_test\n",
        "\n",
        "# Calibrating model probabilities for better score distribution\n",
        "    def calibrate_probabilities(self, X_test, y_test):\n",
        "        print(\"Calibrating probabilities...\")\n",
        "\n",
        "# isotonic calibration\n",
        "        self.calibrated_model = CalibratedClassifierCV(\n",
        "            self.model,\n",
        "            method='isotonic',\n",
        "            cv=5\n",
        "        )\n",
        "\n",
        "# Fit calibration on full scaled dataset\n",
        "        X_full_scaled = self.scaler.fit_transform(self.X)\n",
        "        self.calibrated_model.fit(X_full_scaled, self.y)\n",
        "\n",
        "# Compare calibrated vs uncalibrated probabilities\n",
        "        uncalibrated_probs = self.model.predict_proba(X_test)\n",
        "        calibrated_probs = self.calibrated_model.predict_proba(X_test)\n",
        "\n",
        "# Calculate Brier scores (lower is better)\n",
        "        uncal_brier = brier_score_loss(y_test == 2, uncalibrated_probs[:, 2])\n",
        "        cal_brier = brier_score_loss(y_test == 2, calibrated_probs[:, 2])\n",
        "\n",
        "        print(f\"Uncalibrated Brier Score: {uncal_brier:.4f}\")\n",
        "        print(f\"Calibrated Brier Score: {cal_brier:.4f}\")\n",
        "        print(f\"Calibration Improvement: {((uncal_brier - cal_brier) / uncal_brier * 100):.1f}%\")\n",
        "\n",
        "        return calibrated_probs\n",
        "\n",
        "\n",
        "    def generate_improved_scores(self):\n",
        "        print(\"Generating calibrated risk scores...\")\n",
        "\n",
        "        X_full_scaled = self.scaler.transform(self.X)\n",
        "        calibrated_probs = self.calibrated_model.predict_proba(X_full_scaled)\n",
        "\n",
        "        high_risk_probs = calibrated_probs[:, 2]  # P(high_risk)\n",
        "        percentile_ranks = np.argsort(np.argsort(high_risk_probs)) / len(high_risk_probs)\n",
        "        risk_scores = np.round(percentile_ranks * 1000).astype(int)\n",
        "        alternative_scores = np.round(\n",
        "            high_risk_probs * 600 +\n",
        "            calibrated_probs[:, 1] * 300 +\n",
        "            calibrated_probs[:, 0] * 100\n",
        "        ).astype(int)\n",
        "\n",
        "        final_scores = risk_scores\n",
        "\n",
        "# output dataframe\n",
        "        wallet_scores = pd.DataFrame({\n",
        "            'wallet_id': self.features_df['wallet_address'],\n",
        "            'score': final_scores,\n",
        "            'prob_high_risk': high_risk_probs,\n",
        "            'actual_risk': self.features_df['risk_profile']\n",
        "        })\n",
        "\n",
        "        return wallet_scores\n",
        "\n",
        "# Logistic regression coefficients\n",
        "    def analyze_feature_importance(self):\n",
        "        print(\"\\nLogistic Regression Feature Importance:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        exclude_cols = ['wallet_address', 'risk_profile', 'risk_label', 'most_used_token']\n",
        "        feature_names = [col for col in self.features_df.columns if col not in exclude_cols]\n",
        "\n",
        "        high_risk_coefs = self.model.coef_[2]  # Class 2 = high_risk\n",
        "\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'coefficient': high_risk_coefs,\n",
        "            'abs_coefficient': np.abs(high_risk_coefs)\n",
        "        }).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "        print(\"Top 10 Most Important Features (for High Risk):\")\n",
        "        for i, row in feature_importance.head(10).iterrows():\n",
        "            direction = \"increases\" if row['coefficient'] > 0 else \"decreases\"\n",
        "            print(f\"{row['feature']:30} | {row['coefficient']:8.4f} ({direction} risk)\")\n",
        "\n",
        "        return feature_importance\n",
        "\n",
        "\n",
        "    def validate_score_distribution(self, wallet_scores):\n",
        "\n",
        "        print(f\"\\nScore Distribution Analysis:\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        scores = wallet_scores['score']\n",
        "        print(f\"Mean Score: {scores.mean():.1f}\")\n",
        "        print(f\"Median Score: {scores.median():.1f}\")\n",
        "        print(f\"Standard Deviation: {scores.std():.1f}\")\n",
        "        print(f\"Range: {scores.min()} - {scores.max()}\")\n",
        "\n",
        "        ranges = [\n",
        "            (0, 200, \"Low Risk\"),\n",
        "            (201, 400, \"Low-Medium Risk\"),\n",
        "            (401, 600, \"Medium Risk\"),\n",
        "            (601, 800, \"High Risk\"),\n",
        "            (801, 1000, \"Very High Risk\")\n",
        "        ]\n",
        "\n",
        "        print(f\"\\nScore Range Distribution:\")\n",
        "        for min_score, max_score, label in ranges:\n",
        "            count = len(scores[(scores >= min_score) & (scores <= max_score)])\n",
        "            pct = (count / len(scores)) * 100\n",
        "            print(f\"{label:15} ({min_score:3d}-{max_score:3d}): {count:3d} wallets ({pct:5.1f}%)\")\n",
        "\n",
        "        print(f\"\\nValidation Against Actual Risk Profiles:\")\n",
        "        for risk_profile in ['low_risk', 'medium_risk', 'high_risk']:\n",
        "            subset = wallet_scores[wallet_scores['actual_risk'] == risk_profile]\n",
        "            if len(subset) > 0:\n",
        "                avg_score = subset['score'].mean()\n",
        "                print(f\"{risk_profile:12}: Average Score = {avg_score:.1f}\")\n",
        "\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        print(\"=== Logistic Regression Risk Scoring Pipeline ===\")\n",
        "\n",
        "        feature_cols = self.load_and_prepare_data()\n",
        "        X_test, y_test = self.train_logistic_regression()\n",
        "        self.calibrate_probabilities(X_test, y_test)\n",
        "        wallet_scores = self.generate_improved_scores()\n",
        "        feature_importance = self.analyze_feature_importance()\n",
        "        self.validate_score_distribution(wallet_scores)\n",
        "        wallet_scores[['wallet_id', 'score']].to_csv(\"logistic_wallet_scores.csv\", index=False)\n",
        "        print(f\"\\nFinal scores saved to: logistic_wallet_scores.csv\")\n",
        "\n",
        "        return wallet_scores, feature_importance\n",
        "\n",
        "    def display_final_scores(self, wallet_scores, n_display=15):\n",
        "        print(f\"\\nFinal Logistic Regression Wallet Scores:\")\n",
        "        print(\"=\"*65)\n",
        "        print(f\"{'wallet_id':<45} | {'score'}\")\n",
        "        print(\"-\"*65)\n",
        "        sorted_scores = wallet_scores.sort_values('score', ascending=False)\n",
        "\n",
        "        for _, row in sorted_scores.head(n_display).iterrows():\n",
        "            print(f\"{row['wallet_id']:<45} | {row['score']:4d}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "\n",
        "    lr_model = LogisticRegressionRiskModel()\n",
        "    wallet_scores, feature_importance = lr_model.run_complete_pipeline()\n",
        "    lr_model.display_final_scores(wallet_scores)\n",
        "\n",
        "    return lr_model, wallet_scores, feature_importance\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lr_model, wallet_scores, feature_importance = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fPH25D-qldq",
        "outputId": "31a22e13-9d8b-4e48-a67a-b4d7c840c652"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression Risk Scoring Pipeline ===\n",
            "Loaded 103 wallets\n",
            "Features: 47, Samples: 103\n",
            "Training Logistic Regression model...\n",
            "C=0.1: CV Score = 0.8025\n",
            "C=0.5: CV Score = 0.8675\n",
            "C=1.0: CV Score = 0.8808\n",
            "C=2.0: CV Score = 0.8817\n",
            "C=5.0: CV Score = 0.8950\n",
            "Best C: 5.0\n",
            "Best CV Score: 0.8950\n",
            "Test Accuracy: 0.9615\n",
            "Calibrating probabilities...\n",
            "Uncalibrated Brier Score: 0.0463\n",
            "Calibrated Brier Score: 0.0415\n",
            "Calibration Improvement: 10.3%\n",
            "Generating calibrated risk scores...\n",
            "\n",
            "Logistic Regression Feature Importance:\n",
            "==================================================\n",
            "Top 10 Most Important Features (for High Risk):\n",
            "unique_tokens                  |  -0.6404 (decreases risk)\n",
            "high_gas_risk                  |  -0.6180 (decreases risk)\n",
            "gas_price_std                  |   0.5813 (increases risk)\n",
            "avg_gas_price                  |   0.5589 (increases risk)\n",
            "consecutive_failures           |   0.4004 (increases risk)\n",
            "borrow_count                   |  -0.4001 (decreases risk)\n",
            "token_cDAI                     |   0.3916 (increases risk)\n",
            "max_gas_price                  |   0.3392 (increases risk)\n",
            "amount_trend                   |  -0.3246 (decreases risk)\n",
            "amount_cv                      |  -0.3002 (decreases risk)\n",
            "\n",
            "Score Distribution Analysis:\n",
            "========================================\n",
            "Mean Score: 495.1\n",
            "Median Score: 495.0\n",
            "Standard Deviation: 290.1\n",
            "Range: 0 - 990\n",
            "\n",
            "Score Range Distribution:\n",
            "Low Risk        (  0-200):  21 wallets ( 20.4%)\n",
            "Low-Medium Risk (201-400):  21 wallets ( 20.4%)\n",
            "Medium Risk     (401-600):  20 wallets ( 19.4%)\n",
            "High Risk       (601-800):  21 wallets ( 20.4%)\n",
            "Very High Risk  (801-1000):  20 wallets ( 19.4%)\n",
            "\n",
            "Validation Against Actual Risk Profiles:\n",
            "low_risk    : Average Score = 153.7\n",
            "medium_risk : Average Score = 737.8\n",
            "high_risk   : Average Score = 354.1\n",
            "\n",
            "Final scores saved to: logistic_wallet_scores.csv\n",
            "\n",
            "Final Logistic Regression Wallet Scores:\n",
            "=================================================================\n",
            "wallet_id                                     | score\n",
            "-----------------------------------------------------------------\n",
            "0xf60304b534f74977e159b2e159e135475c245526    |  990\n",
            "0xf340b9f2098f80b86fbc5ede586c319473aa11f3    |  981\n",
            "0xc22b8e78394ce52e0034609a67ae3c959daa84bc    |  971\n",
            "0xd0df53e296c1e3115fccc3d7cdf4ba495e593b56    |  961\n",
            "0xcbbd9fe837a14258286bbf2e182cbc4e4518c5a3    |  951\n",
            "0xde92d70253604fd8c5998c8ee3ed282a41b33b7f    |  942\n",
            "0xeded1c8c0a0c532195b8432153f3bfa81dba2a90    |  932\n",
            "0x9a363adc5d382c04d36b09158286328f75672098    |  922\n",
            "0x96bb4447a02b95f1d1e85374cffd565eb22ed2f8    |  913\n",
            "0x330513970efd9e8dd606275fb4c50378989b3204    |  903\n",
            "0x3867d222ba91236ad4d12c31056626f9e798629c    |  893\n",
            "0x24b3460622d835c56d9a4fe352966b9bdc6c20af    |  883\n",
            "0x2a2fde3e1beb508fcf7c137a1d5965f13a17825e    |  874\n",
            "0x104ae61d8d487ad689969a17807ddc338b445416    |  864\n",
            "0x06b51c6882b27cb05e712185531c1f74996dd988    |  854\n"
          ]
        }
      ]
    }
  ]
}